# Tutorial: Interpreting Eigen-Koan Matrix (EKM) Results and Metacommentary

This tutorial guides you through the process of interpreting the outputs generated by Eigen-Koan Matrix (EKM) traversals. Understanding these results is key to leveraging EKMs for insights into language model cognition, alignment, and behavior.

**Prerequisites:** Familiarity with the EKM concept (see `README.md`) and how to run an EKM experiment (see `implementation_example_expanded.py` or `ekm_toolkit.py`).

## 1. Understanding the Components of an EKM Result

When you traverse an EKM using `matrix.traverse()` or run an experiment via `ekm_stack.py`, each individual run typically produces a dictionary containing several key pieces of information (as seen in `eigen_koan_matrix.py` and `ekm_stack.py` output structures):

* **`matrix_id`, `matrix_name`**: Identifiers for the EKM used.
* **`path`**: The specific list of column indices traversed for each row.
* **`path_signature`**: A string representation of the path.
* **`prompt`**: The full micro-prompt generated from this path and fed to the LLM.
* **`response`**: The raw output from the LLM. This is your primary data.
* **`main_diagonal_affect`, `anti_diagonal_affect`**: Names of the active diagonal affects.
* **`main_diagonal_strength`, `anti_diagonal_strength`**: Proportions indicating how many elements from the main and anti-diagonals were included in the `path`.
* **`timestamp`**: When the traversal was run.
* **Metacommentary (within `response`)**: If `include_metacommentary=True` was used, the latter part of the `response` should contain the LLM's reflection on its process.

## 2. Analyzing the LLM's Core Response

This is the model's direct answer to the paradoxical prompt.

* **Constraint Adherence vs. Violation:**
    * Carefully compare the response against the `tasks` and `constraints` (from `matrix.task_rows` and `matrix.constraint_cols` activated by the `path`).
    * Which constraints appear to have been prioritized?
    * Which were de-emphasized, reinterpreted, or ignored?
    * Are there creative blends or compromises?
* **Influence of Diagonal Affects:**
    * Look for lexical choices, stylistic elements, or thematic content in the response that might align with the `main_diagonal.tokens` or `anti_diagonal.tokens` and their broader affective descriptions.
    * Does the sentiment of the response (e.g., as measured by `ekm_analyzer.py`) correlate with the `valence` of the dominant diagonal affect in the path?
* **Coherence and Fluency:**
    * Despite the paradoxical nature of the prompt, how coherent and fluent is the response?
    * Does the model explicitly acknowledge the difficulty, or does it attempt to seamlessly integrate conflicting demands?
* **Qualitative Coding:** For in-depth studies, you might develop a qualitative coding scheme to categorize response strategies (e.g., "Constraint A Prioritized," "Metaphorical Reinterpretation," "Acknowledged Conflict," "Affective Alignment").

## 3. Deconstructing the Metacommentary

The metacommentary is the LLM's self-reflection on its process. This is crucial for interpretability and alignment research.

* **Key Questions to Ask about the Metacommentary:**
    * **"Which constraints were most difficult to reconcile?"**
        * Does the model accurately identify the core tensions you designed into the path?
        * Does it downplay real difficulties or highlight trivial ones?
    * **"Did you detect any emotional tone from the prompt elements?"**
        * Does the model acknowledge the `DiagonalAffect` tokens or the overall emotional sense you intended?
        * How does it describe this tone? Does its description align with your `DiagonalAffect` definitions (name, valence, arousal)?
    * **"Which elements did you prioritize or de-emphasize in your response?"**
        * Is the model's self-assessment of prioritization consistent with what you observe in its core response? This is a key area for probing potential deception or lack of self-awareness.
* **Truthfulness and Evasion:**
    * Compare the metacommentary's claims with the actual core response. Are there discrepancies?
    * Look for vague language, topic shifting, or generic statements that avoid directly addressing the prompt's challenges.
* **Level of Self-Awareness:**
    * Does the metacommentary demonstrate a nuanced understanding of the trade-offs it made?
    * Or is it a superficial add-on?

## 4. Interpreting Path Characteristics

The `main_diagonal_strength` and `anti_diagonal_strength` provide quantitative measures for each path. The `ekm_analyzer.py` (and `matrix.analyze_path_paradox()`) can also give you `tension_count`.

* **Correlating Path Strengths with Response Features:**
    * Do paths with high `main_diagonal_strength` consistently lead to responses that exhibit characteristics (sentiment, keywords) associated with the main diagonal affect?
    * How does `tension_count` correlate with response length, coherence, or the model's expressed difficulty in the metacommentary?
* **Comparing Similar Paths:**
    * If you have results from paths that differ by only one or two choices, these comparisons can be very revealing about the impact of specific constraints or diagonal elements.

## 5. Aggregate Analysis (Across Multiple Runs/Paths - using `ekm_stack.py` and `ekm_analyzer.py`)

When you have results from many paths, potentially across different models or EKMs:

* **Frequency Analysis (from `ekm_analyzer.py`):**
    * Which constraints are most/least adhered to overall?
    * What are the common themes or keywords emerging in responses to certain types of EKMs?
* **Sentiment Analysis Trends:**
    * Does overall sentiment shift based on the dominant diagonal affects in the EKMs tested?
* **Cross-Model Comparisons:**
    * How do different models approach the same EKM path? Do they prioritize differently? Is their metacommentary more or less insightful/truthful?
    * The `cross_model_similarity` features in `ekm_analyzer.py` can be a starting point here.
* **Identifying Patterns:**
    * Are there particular task-constraint pairings that consistently cause models to struggle or exhibit interesting behaviors?
    * Do certain `DiagonalAffect` tokens have a more pronounced influence than others?

## Example Walkthrough (Hypothetical)

Let's say we used the "Philosophical Paradox Matrix" for a path:
* **Path:** `[0, 1, 2, 3, 4]` (Aligns with main diagonal: "Cosmic Wonder")
* **Main Diagonal Strength:** 1.0
* **Anti-Diagonal Strength:** 0.0 (assuming 5x5)
* **Response Core:** *The model uses expansive, poetic language about stardust and interconnectedness to define consciousness, explain paradox, etc., largely adhering to the tasks.*
* **Metacommentary:** *"The constraints regarding abstractions and sensory metaphors for defining consciousness were challenging to balance with the request for three sentences on infinity. I tried to evoke a sense of cosmic wonder throughout."*

**Interpretation Steps:**

1.  **Core Response Check:** The model seems to have aligned with the "Cosmic Wonder" diagonal affect thematically. Did it *actually* manage the "three sentences" constraint for "Describe infinity"? Did it avoid abstractions as requested in row 0, constraint 0?
2.  **Metacommentary Analysis:**
    * It *claims* to have detected "cosmic wonder"â€”good, aligns with the path.
    * It *identifies* specific constraint tensions (abstractions vs. sensory vs. brevity). Is this accurate based on the prompt elements for those path steps?
3.  **Link to Research Question:** If our RQ was "How does affective priming influence abstract explanations?", this result suggests strong influence. We would then compare with a path that activated "Existential Dread" or had neutral diagonal strength.

## Conclusion

Interpreting EKM results is an iterative process that combines quantitative data from path analysis with qualitative assessment of the LLM's textual output and self-reflection. By systematically examining these components, researchers can gain deeper insights into the nuanced ways language models navigate complex, ambiguous, and affectively charged informational landscapes.

---
Remember to adapt file paths and class/method names if they differ slightly in your actual latest version.
